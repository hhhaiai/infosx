# train_pipeline.py
import pandas as pd
import numpy as np
import lightgbm as lgb  # æ ¸å¿ƒå˜åŒ–
import os
import glob
from onnxmltools import convert_lightgbm
from onnxconverter_common.data_types import FloatTensorType
import config
from feature_engine import FeatureEngine

def load_recent_data(days=3):
    """åŠ è½½æœ€è¿‘ N å¤©çš„æ•°æ®"""
    files = sorted(glob.glob(os.path.join(config.DATA_DIR, "*.csv")))
    if not files:
        raise FileNotFoundError("æœªæ‰¾åˆ°æ•°æ®æ–‡ä»¶ï¼Œè¯·å…ˆè¿è¡Œ data_collector.py")
    
    recent_files = files[-days:]
    print(f"ğŸ“š [Train] åŠ è½½æ–‡ä»¶: {[os.path.basename(f) for f in recent_files]}")
    
    df_list = []
    for f in recent_files:
        try:
            df_list.append(pd.read_csv(f))
        except Exception as e:
            print(f"âš ï¸ è·³è¿‡æŸåæ–‡ä»¶ {f}: {e}")
            
    return pd.concat(df_list, ignore_index=True)

def train_model():
    # 1. åŠ è½½æ•°æ®
    df = load_recent_data(days=3)
    print(f"ğŸ“Š [Train] åŸå§‹æ•°æ®è¡Œæ•°: {len(df)}")
    
    # 2. ç‰¹å¾è®¡ç®—
    X = FeatureEngine.calculate_train_features(df)
    
    # 3. æ‰“æ ‡ç­¾
    mid_price = (df['ap0'] + df['bp0']) / 2
    future_return = mid_price.shift(-config.PREDICT_HORIZON) / mid_price - 1
    
    y = np.zeros(len(df))
    y[future_return > config.LABEL_THRESHOLD] = 1
    
    valid_idx = ~np.isnan(future_return)
    X = X[valid_idx]
    y = y[valid_idx]
    
    print(f"ğŸ¯ [Train] æ­£æ ·æœ¬(ä¹°å…¥æœºä¼š)æ¯”ä¾‹: {np.mean(y==1):.2%}")
    
    # 4. è®­ç»ƒ LightGBM
    print("ğŸš€ [Train] å¼€å§‹è®­ç»ƒ LightGBM...")
    
    # LGBM å‚æ•°é…ç½® (æ³¨é‡é€Ÿåº¦ä¸æ³›åŒ–)
    model = lgb.LGBMClassifier(
        n_estimators=100,
        learning_rate=0.1,
        num_leaves=31,        # LGBM æ ¸å¿ƒå‚æ•°ï¼Œæ§åˆ¶å¤æ‚åº¦
        max_depth=-1,         # -1 è¡¨ç¤ºä¸é™åˆ¶æ·±åº¦ï¼Œç”± num_leaves æ§åˆ¶
        n_jobs=-1,            # ä½¿ç”¨æ‰€æœ‰ CPU æ ¸å¿ƒ
        objective='binary',
        importance_type='split'
    )
    
    model.fit(
        X, y,
        eval_set=[(X, y)],     # ç®€å•è‡ªæµ‹ï¼Œå®é™…åº”ç”¨åº”åˆ’åˆ†éªŒè¯é›†
        eval_metric='logloss',
        callbacks=[
            lgb.log_evaluation(period=20) # æ¯20è½®æ‰“å°ä¸€æ¬¡æ—¥å¿—
        ]
    )
    
    # 5. å¯¼å‡º ONNX
    print("ğŸ’¾ [Train] æ­£åœ¨å¯¼å‡º ONNX...")
    
    # å®šä¹‰è¾“å…¥å¼ é‡çš„ç±»å‹å’Œå½¢çŠ¶: [Batch_Size, Feature_Count]
    initial_type = [('input', FloatTensorType([None, len(config.FEATURES)]))]
    
    # ä½¿ç”¨ onnxmltools è½¬æ¢
    onx = convert_lightgbm(
        model, 
        initial_types=initial_type,
        target_opset=12
    )
    
    save_path = os.path.join(config.MODEL_DIR, "hft_model_lgbm.onnx")
    with open(save_path, "wb") as f:
        f.write(onx.SerializeToString())
        
    print(f"âœ… [Train] æ¨¡å‹å·²ä¿å­˜: {save_path}")

if __name__ == "__main__":
    train_model()