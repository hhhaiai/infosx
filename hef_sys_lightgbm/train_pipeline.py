# train_pipeline.py
import pandas as pd
import numpy as np
import lightgbm as lgb
import os
import glob
from onnxmltools import convert_lightgbm
from onnxconverter_common.data_types import FloatTensorType
import config
from feature_engine import FeatureEngine

def load_recent_data(days=5):
    """åŠ è½½æœ€è¿‘ N å¤©çš„æ•°æ®"""
    files = sorted(glob.glob(os.path.join(config.DATA_DIR, "*.csv")))
    if not files:
        print("âš ï¸ æœªæ‰¾åˆ°æ•°æ®æ–‡ä»¶ï¼è¯·å…ˆè¿è¡Œ data_collector.py å½•åˆ¶å‡ åˆ†é’Ÿæ•°æ®ã€‚")
        return None
    
    recent_files = files[-days:]
    print(f"ğŸ“š [Train] åŠ è½½æ–‡ä»¶: {[os.path.basename(f) for f in recent_files]}")
    
    df_list = []
    for f in recent_files:
        try:
            # ç®€å•æ£€æŸ¥æ–‡ä»¶æ˜¯å¦ä¸ºç©º
            if os.path.getsize(f) < 100: continue
            df_list.append(pd.read_csv(f))
        except Exception as e:
            print(f"âš ï¸ è·³è¿‡æŸåæ–‡ä»¶ {f}: {e}")
            
    if not df_list: return None
    return pd.concat(df_list, ignore_index=True)

def train_model():
    # 1. åŠ è½½æ•°æ®
    df = load_recent_data()
    if df is None: return
    
    print(f"ğŸ“Š [Train] åŸå§‹æ•°æ®è¡Œæ•°: {len(df)}")
    
    # 2. ç‰¹å¾è®¡ç®—
    print("âš™ï¸ [Train] æ­£åœ¨è®¡ç®—ç‰¹å¾...")
    X = FeatureEngine.calculate_train_features(df)
    
    # 3. æ‰“æ ‡ç­¾
    # è®¡ç®—æœªæ¥ä»·æ ¼å˜åŒ–ç‡
    mid_price = (df['ap0'] + df['bp0']) / 2
    future_return = mid_price.shift(-config.PREDICT_HORIZON) / mid_price - 1
    
    # Label: 1 = æ¶¨å¹…è¶…è¿‡é˜ˆå€¼, 0 = å…¶ä»–
    y = np.zeros(len(df))
    y[future_return > config.LABEL_THRESHOLD] = 1
    
    # æ¸…æ´—æ— æ•ˆæ•°æ® (NaN)
    valid_idx = ~np.isnan(future_return) & ~X.isnull().any(axis=1)
    X = X[valid_idx]
    y = y[valid_idx]
    
    pos_ratio = np.mean(y==1)
    print(f"ğŸ¯ [Train] æ­£æ ·æœ¬(ä¹°å…¥ä¿¡å·)æ¯”ä¾‹: {pos_ratio:.2%}")
    
    if len(X) < 1000:
        print("âš ï¸ æ•°æ®é‡å¤ªå°‘ï¼Œæ— æ³•æœ‰æ•ˆè®­ç»ƒã€‚è¯·ç»§ç»­å½•åˆ¶ã€‚")
        return

    # 4. è®­ç»ƒ LightGBM
    print("ğŸš€ [Train] å¼€å§‹è®­ç»ƒ LightGBM...")
    model = lgb.LGBMClassifier(
        n_estimators=200,
        learning_rate=0.05,
        num_leaves=31,
        max_depth=-1,
        n_jobs=-1,
        objective='binary',
        random_state=42
    )
    
    model.fit(X, y)
    
    # 5. å¯¼å‡º ONNX
    print("ğŸ’¾ [Train] æ­£åœ¨å¯¼å‡º ONNX...")
    
    # å®šä¹‰è¾“å…¥å¼ é‡å½¢çŠ¶: [Batch_Size, Feature_Count]
    # float ç±»å‹å¿…é¡»åŒ¹é…
    initial_type = [('input', FloatTensorType([None, len(config.FEATURES)]))]
    
    # è½¬æ¢
    onx = convert_lightgbm(
        model, 
        initial_types=initial_type,
        target_opset=12
    )
    
    save_path = os.path.join(config.MODEL_DIR, config.MODEL_NAME)
    with open(save_path, "wb") as f:
        f.write(onx.SerializeToString())
        
    print(f"âœ… [Train] æ¨¡å‹å·²ä¿å­˜: {save_path}")

if __name__ == "__main__":
    train_model()