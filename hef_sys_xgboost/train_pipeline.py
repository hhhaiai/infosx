# train_pipeline.py
import pandas as pd
import numpy as np
import xgboost as xgb
import os
import glob
from skl2onnx import to_onnx, update_registered_converter
from skl2onnx.common.shape_calculator import calculate_linear_classifier_output_shapes
from onnxmltools.convert.xgboost.operator_converters.xgboost import convert_xgboost
import config
from feature_engine import FeatureEngine

# æ³¨å†Œ ONNX è½¬æ¢å™¨
update_registered_converter(
    xgb.XGBClassifier, 'XGBoostXGBClassifier',
    calculate_linear_classifier_output_shapes, convert_xgboost, 
    options={'nocl': [True, False], 'zipmap': [False]}
)

def load_recent_data(days=3):
    """
    åŠ è½½æœ€è¿‘ N å¤©çš„ CSV æ•°æ®æ–‡ä»¶ã€‚
    
    Args:
        days (int): å›æº¯çš„å¤©æ•°ï¼Œé»˜è®¤ä¸º 3ã€‚
        
    Returns:
        pd.DataFrame: åˆå¹¶åçš„ Pandas DataFrameï¼ŒåŒ…å«æ‰€æœ‰åŠ è½½çš„æ•°æ®ã€‚
        
    Raises:
        FileNotFoundError: å¦‚æœæ²¡æœ‰æ‰¾åˆ°ä»»ä½•æ•°æ®æ–‡ä»¶ã€‚
    """
    files = sorted(glob.glob(os.path.join(config.DATA_DIR, "*.csv")))
    if not files:
        raise FileNotFoundError("æœªæ‰¾åˆ°æ•°æ®æ–‡ä»¶ï¼Œè¯·å…ˆè¿è¡Œ data_collector.py")
    
    recent_files = files[-days:]
    print(f"ğŸ“š [Train] åŠ è½½æ–‡ä»¶: {[os.path.basename(f) for f in recent_files]}")
    
    df_list = []
    for f in recent_files:
        try:
            df_list.append(pd.read_csv(f))
        except Exception as e:
            print(f"âš ï¸ è·³è¿‡æŸåæ–‡ä»¶ {f}: {e}")
            
    return pd.concat(df_list, ignore_index=True)

def train_model():
    """
    æ¨¡å‹è®­ç»ƒä¸»æµç¨‹ã€‚
    
    æ­¥éª¤:
    1. åŠ è½½æœ€è¿‘çš„å†å²æ•°æ®ã€‚
    2. è®¡ç®—ç‰¹å¾ (Feature Engineering)ã€‚
    3. ç”Ÿæˆæ ‡ç­¾ (Labeling) - åŸºäºæœªæ¥æ”¶ç›Šç‡ã€‚
    4. è®­ç»ƒ XGBoost åˆ†ç±»æ¨¡å‹ã€‚
    5. å°†è®­ç»ƒå¥½çš„æ¨¡å‹å¯¼å‡ºä¸º ONNX æ ¼å¼ï¼Œä»¥ä¾¿äºé«˜æ€§èƒ½æ¨ç†ã€‚
    """
    # 1. åŠ è½½æ•°æ®
    df = load_recent_data(days=3)
    print(f"ğŸ“Š [Train] åŸå§‹æ•°æ®è¡Œæ•°: {len(df)}")
    
    # 2. ç‰¹å¾è®¡ç®—
    X = FeatureEngine.calculate_train_features(df)
    
    # 3. æ‰“æ ‡ç­¾ (Labeling)
    mid_price = (df['ap0'] + df['bp0']) / 2
    # è®¡ç®—æœªæ¥æ”¶ç›Šç‡
    future_return = mid_price.shift(-config.PREDICT_HORIZON) / mid_price - 1
    
    # ä¸‰åˆ†ç±»æ ‡ç­¾: 1(Buy), 0(Hold/Sell) 
    # æ³¨ï¼šå½“å‰ç®€åŒ–ä¸ºäºŒåˆ†ç±»ï¼Œåªé¢„æµ‹ä¹°ç‚¹
    y = np.zeros(len(df))
    y[future_return > config.LABEL_THRESHOLD] = 1
    
    # æ¸…æ´—æ ‡ç­¾ä¸ºç©ºçš„è¡Œ
    valid_idx = ~np.isnan(future_return)
    X = X[valid_idx]
    y = y[valid_idx]
    
    print(f"ğŸ¯ [Train] æ­£æ ·æœ¬(ä¹°å…¥æœºä¼š)æ¯”ä¾‹: {np.mean(y==1):.2%}")
    
    # 4. è®­ç»ƒ XGBoost
    print("ğŸš€ [Train] å¼€å§‹è®­ç»ƒ (ä½¿ç”¨ hist æ¨¡å¼)...")
    model = xgb.XGBClassifier(
        n_estimators=100,
        max_depth=5,
        learning_rate=0.1,
        tree_method='hist',  # CPU é«˜é€Ÿæ¨¡å¼
        n_jobs=-1,
        objective='binary:logistic'
    )
    model.fit(X, y)
    
    # 5. å¯¼å‡º ONNX
    print("ğŸ’¾ [Train] æ­£åœ¨å¯¼å‡º ONNX...")
    onx = to_onnx(
        model, 
        X[:1].astype(np.float32), 
        target_opset=12
    )
    
    save_path = os.path.join(config.MODEL_DIR, "hft_model_latest.onnx")
    with open(save_path, "wb") as f:
        f.write(onx.SerializeToString())
        
    print(f"âœ… [Train] æ¨¡å‹å·²ä¿å­˜: {save_path}")

if __name__ == "__main__":
    train_model()